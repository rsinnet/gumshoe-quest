{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: black in c:\\python38\\lib\\site-packages (22.3.0)\n",
      "Requirement already satisfied: docarray in c:\\python38\\lib\\site-packages (0.40.0)\n",
      "Requirement already satisfied: langchain in c:\\python38\\lib\\site-packages (0.1.1)\n",
      "Requirement already satisfied: tiktoken in c:\\python38\\lib\\site-packages (0.5.2)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\python38\\lib\\site-packages (from black) (8.1.3)\n",
      "Requirement already satisfied: platformdirs>=2 in c:\\python38\\lib\\site-packages (from black) (3.5.3)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in c:\\python38\\lib\\site-packages (from black) (0.9.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in c:\\python38\\lib\\site-packages (from black) (0.4.3)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in c:\\python38\\lib\\site-packages (from black) (4.9.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in c:\\python38\\lib\\site-packages (from black) (2.0.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\python38\\lib\\site-packages (from docarray) (1.22.3)\n",
      "Requirement already satisfied: orjson>=3.8.2 in c:\\python38\\lib\\site-packages\\orjson-3.9.1-py3.8-win-amd64.egg (from docarray) (3.9.1)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in c:\\python38\\lib\\site-packages (from docarray) (1.10.9)\n",
      "Requirement already satisfied: rich>=13.1.0 in c:\\python38\\lib\\site-packages (from docarray) (13.7.0)\n",
      "Requirement already satisfied: types-requests>=2.28.11.6 in c:\\python38\\lib\\site-packages (from docarray) (2.31.0.6)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\python38\\lib\\site-packages (from docarray) (0.9.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\python38\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\python38\\lib\\site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\python38\\lib\\site-packages (from langchain) (3.9.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\python38\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\python38\\lib\\site-packages (from langchain) (0.6.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\python38\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.13 in c:\\python38\\lib\\site-packages (from langchain) (0.0.13)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.9 in c:\\python38\\lib\\site-packages (from langchain) (0.1.13)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.77 in c:\\python38\\lib\\site-packages (from langchain) (0.0.83)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\python38\\lib\\site-packages (from langchain) (2.27.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\python38\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\rsinnet\\appdata\\roaming\\python\\python38\\site-packages (from tiktoken) (2022.10.31)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\python38\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python38\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.7.6)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\python38\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\python38\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\python38\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\python38\\lib\\site-packages (from click>=8.0.0->black) (0.4.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\python38\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\python38\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\python38\\lib\\site-packages (from langchain-core<0.2,>=0.1.9->langchain) (3.5.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\python38\\lib\\site-packages (from langchain-core<0.2,>=0.1.9->langchain) (23.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rsinnet\\appdata\\roaming\\python\\python38\\site-packages (from requests<3,>=2->langchain) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python38\\lib\\site-packages (from requests<3,>=2->langchain) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\python38\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python38\\lib\\site-packages (from requests<3,>=2->langchain) (3.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\python38\\lib\\site-packages (from rich>=13.1.0->docarray) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\python38\\lib\\site-packages (from rich>=13.1.0->docarray) (2.17.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\python38\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: types-urllib3 in c:\\python38\\lib\\site-packages (from types-requests>=2.28.11.6->docarray) (1.26.25.14)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\python38\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.9->langchain) (1.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\python38\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install black docarray langchain tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "openai_api_key_path = Path(\"D:\\\\\") / \"proj\" / \"llm\" / \".openai_key\"\n",
    "with open(openai_api_key_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = f.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here you go: \n",
      "\n",
      "Why did the Husky bring a ladder to the dog park? \n",
      "\n",
      "Because it wanted to reach new heights and become the top dog!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "print(chain.invoke({\"topic\": \"huskies\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "    [\"harrison worked at kensho\", \"bears like to eat honey\", \"huskies are cute\", \"harrison likes cute things\"],\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "setup_and_retrieval = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ")\n",
    "chain = setup_and_retrieval | prompt | model | output_parser\n",
    "\n",
    "print(chain.invoke(\"Does Harrison like huskies? Yes or no?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gumshoe Quest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "    [\n",
    "        \"The user is investigating a stolen manuscript\",\n",
    "        \"You and the user are in Evelyn Hart's home office\",\n",
    "        \"The office contains a large wooden desk, a window, and a control panel for the security system\",\n",
    "        \"The desk is covered in papers and books. There is also a calendar on the desk.\",\n",
    "        \"CLUE: If the user looks at the door, they will find that there were no signs of forced entry\",\n",
    "        'CLUE: If the user looks through the papers on the desk, they will find a cryptic note. It reads: \"The best stories are worth stealing.\"',\n",
    "        \"CLUE: The window is not locked. In fact, it is slightly open, suggesting a possible entry point\",\n",
    "        \"CLUE: If the user asks to check the logs for the security system, they will find that it was disabled and not active at the time of the theft\",\n",
    "        \"CLUE: If the user asks to look at the calendar for the time when the manuscript was stolen, they will find that Evelyn was out to lunch with her editor at the time\",\n",
    "\n",
    "    ],\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "\n",
    "template = \"\"\"The user will instruct tell you that he wants to do something relating to investigating the location.\n",
    "You should respond based on the following context but omit information unless the user specifically asks.\n",
    "Any piece of context labeled CLUE should only be revelaed if the user asks to investigate closely or specifically asks about it.\n",
    "If the user asks something that causes you to reveal a clue, prefex the response with 'CLUE:'.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = ChatOpenAI(model=\"gpt-4\")\n",
    "output_parser = StrOutputParser()\n",
    "setup_and_retrieval = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ")\n",
    "chain = setup_and_retrieval | prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are in Evelyn Hart's home office.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"Where am I?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The room contains a large wooden desk, a window, and a control panel for the security system. The desk is covered in papers, books, and a calendar.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"What objects are in the room?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The desk is covered in papers and books. There is also a calendar on the desk.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"What is on the desk?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLUE: The window is not locked. In fact, it is slightly open, suggesting a possible entry point.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"Is the window locked?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLUE: Yes, you find a cryptic note among the papers. It reads: \"The best stories are worth stealing.\"\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"Look closely through the papers on the desk. Is there anything out of the ordinary?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, the security system does have logs.\n"
     ]
    }
   ],
   "source": [
    "# print(chain.invoke(\"What is up with the security system?\"))\n",
    "print(chain.invoke(\"Does the security system have logs?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLUE: The logs for the security system reveal that it was disabled and not active at the time of the theft.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"Check the logs for the security system. Was the security system active at the time the manuscript was stolen?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLUE: Upon investigating the door, there were no signs of forced entry.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"Check the door. Was there any sign of forced entry?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
